{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Autoencoder â€“ Anomaly Detection\n",
    "\n",
    "This notebook implements an Autoencoder-based anomaly detection model\n",
    "for fraud detection.\n",
    "\n",
    "The model is trained only on normal transactions and uses reconstruction\n",
    "error to identify anomalous (fraudulent) transactions. Performance is\n",
    "evaluated on a validation set containing both normal and fraud samples.\n"
   ],
   "id": "df081efe23872533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:45:56.716165Z",
     "start_time": "2026-01-09T03:45:56.644322200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "print(\"MLPRegressor imported successfully\")\n"
   ],
   "id": "3778f5f42e861c79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor imported successfully\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:45:32.393061100Z",
     "start_time": "2026-01-09T03:45:32.200548500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Load Preprocessed Data\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "\n",
    "ARTIFACT_DIR = \"../models\"\n",
    "\n",
    "X_train_scaled = np.load(f\"{ARTIFACT_DIR}/X_train_scaled.npy\")\n",
    "X_val_scaled = np.load(f\"{ARTIFACT_DIR}/X_val_scaled.npy\")\n",
    "y_val = np.load(f\"{ARTIFACT_DIR}/y_val.npy\")\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(\"X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"X_val_scaled:\", X_val_scaled.shape)\n",
    "print(\"y_val:\", y_val.shape)\n"
   ],
   "id": "201df9e587979b94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "X_train_scaled: (227452, 38)\n",
      "X_val_scaled: (57355, 38)\n",
      "y_val: (57355,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:53:20.558724700Z",
     "start_time": "2026-01-09T03:51:36.020252800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Train Autoencoder (sklearn)\n",
    "# -----------------------------\n",
    "# Autoencoder is implemented by training MLPRegressor to reconstruct input\n",
    "\n",
    "autoencoder = MLPRegressor(\n",
    "    hidden_layer_sizes=(32, 16, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=100,\n",
    "    batch_size=256,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training autoencoder on normal transactions...\")\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled)\n",
    "\n",
    "print(\"Autoencoder training completed.\")\n"
   ],
   "id": "654cca4079c9e6d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder on normal transactions...\n",
      "Iteration 1, loss = 0.28493462\n",
      "Iteration 2, loss = 0.18193088\n",
      "Iteration 3, loss = 0.15714369\n",
      "Iteration 4, loss = 0.14417441\n",
      "Iteration 5, loss = 0.13515417\n",
      "Iteration 6, loss = 0.12939991\n",
      "Iteration 7, loss = 0.12405058\n",
      "Iteration 8, loss = 0.11488047\n",
      "Iteration 9, loss = 0.10836408\n",
      "Iteration 10, loss = 0.10562839\n",
      "Iteration 11, loss = 0.10382273\n",
      "Iteration 12, loss = 0.10240649\n",
      "Iteration 13, loss = 0.10103771\n",
      "Iteration 14, loss = 0.09983008\n",
      "Iteration 15, loss = 0.09878532\n",
      "Iteration 16, loss = 0.09778978\n",
      "Iteration 17, loss = 0.09704785\n",
      "Iteration 18, loss = 0.09651044\n",
      "Iteration 19, loss = 0.09614237\n",
      "Iteration 20, loss = 0.09575935\n",
      "Iteration 21, loss = 0.09548136\n",
      "Iteration 22, loss = 0.09519488\n",
      "Iteration 23, loss = 0.09488328\n",
      "Iteration 24, loss = 0.09461577\n",
      "Iteration 25, loss = 0.09460022\n",
      "Iteration 26, loss = 0.09415551\n",
      "Iteration 27, loss = 0.09397365\n",
      "Iteration 28, loss = 0.09390484\n",
      "Iteration 29, loss = 0.09380569\n",
      "Iteration 30, loss = 0.09366143\n",
      "Iteration 31, loss = 0.09354450\n",
      "Iteration 32, loss = 0.09329850\n",
      "Iteration 33, loss = 0.09325532\n",
      "Iteration 34, loss = 0.09329299\n",
      "Iteration 35, loss = 0.09302506\n",
      "Iteration 36, loss = 0.09299677\n",
      "Iteration 37, loss = 0.09286636\n",
      "Iteration 38, loss = 0.09274240\n",
      "Iteration 39, loss = 0.09271363\n",
      "Iteration 40, loss = 0.09260042\n",
      "Iteration 41, loss = 0.09251492\n",
      "Iteration 42, loss = 0.09246410\n",
      "Iteration 43, loss = 0.09229521\n",
      "Iteration 44, loss = 0.09225645\n",
      "Iteration 45, loss = 0.09210460\n",
      "Iteration 46, loss = 0.09206237\n",
      "Iteration 47, loss = 0.09200201\n",
      "Iteration 48, loss = 0.09200319\n",
      "Iteration 49, loss = 0.09182762\n",
      "Iteration 50, loss = 0.09165899\n",
      "Iteration 51, loss = 0.09154124\n",
      "Iteration 52, loss = 0.09163990\n",
      "Iteration 53, loss = 0.09134625\n",
      "Iteration 54, loss = 0.09134279\n",
      "Iteration 55, loss = 0.09137499\n",
      "Iteration 56, loss = 0.09114754\n",
      "Iteration 57, loss = 0.09113047\n",
      "Iteration 58, loss = 0.09087693\n",
      "Iteration 59, loss = 0.09095527\n",
      "Iteration 60, loss = 0.09069626\n",
      "Iteration 61, loss = 0.09060088\n",
      "Iteration 62, loss = 0.09068478\n",
      "Iteration 63, loss = 0.09036224\n",
      "Iteration 64, loss = 0.09029448\n",
      "Iteration 65, loss = 0.09026084\n",
      "Iteration 66, loss = 0.09012713\n",
      "Iteration 67, loss = 0.09011462\n",
      "Iteration 68, loss = 0.08997614\n",
      "Iteration 69, loss = 0.08980787\n",
      "Iteration 70, loss = 0.08975157\n",
      "Iteration 71, loss = 0.08972047\n",
      "Iteration 72, loss = 0.08963900\n",
      "Iteration 73, loss = 0.08972654\n",
      "Iteration 74, loss = 0.08932997\n",
      "Iteration 75, loss = 0.08922815\n",
      "Iteration 76, loss = 0.08916234\n",
      "Iteration 77, loss = 0.08923090\n",
      "Iteration 78, loss = 0.08907768\n",
      "Iteration 79, loss = 0.08906165\n",
      "Iteration 80, loss = 0.08895113\n",
      "Iteration 81, loss = 0.08905317\n",
      "Iteration 82, loss = 0.08888979\n",
      "Iteration 83, loss = 0.08899435\n",
      "Iteration 84, loss = 0.08884100\n",
      "Iteration 85, loss = 0.08883627\n",
      "Iteration 86, loss = 0.08901150\n",
      "Iteration 87, loss = 0.08878238\n",
      "Iteration 88, loss = 0.08884759\n",
      "Iteration 89, loss = 0.08875700\n",
      "Iteration 90, loss = 0.08882123\n",
      "Iteration 91, loss = 0.08893775\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Autoencoder training completed.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:55:00.116256100Z",
     "start_time": "2026-01-09T03:54:59.937942600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Reconstruction Error\n",
    "# -----------------------------\n",
    "# The autoencoder tries to reconstruct normal transactions.\n",
    "# Higher reconstruction error => more anomalous => more likely fraud.\n",
    "\n",
    "# Reconstruct validation data\n",
    "X_val_recon = autoencoder.predict(X_val_scaled)\n",
    "\n",
    "# Mean Squared Error per transaction\n",
    "recon_error = np.mean((X_val_scaled - X_val_recon) ** 2, axis=1)\n",
    "\n",
    "print(\"Reconstruction error computed successfully\")\n",
    "print(\"Reconstruction error statistics:\")\n",
    "print(\"Min:\", recon_error.min())\n",
    "print(\"Max:\", recon_error.max())\n",
    "print(\"Mean:\", recon_error.mean())\n",
    "print(\"Std:\", recon_error.std())\n"
   ],
   "id": "6aad05e88857c42b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error computed successfully\n",
      "Reconstruction error statistics:\n",
      "Min: 0.005939563733622087\n",
      "Max: 38.55350006530182\n",
      "Mean: 0.20513079251561092\n",
      "Std: 0.6157717350340094\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reconstruction Error Analysis\n",
    "\n",
    "The reconstruction error was computed for all validation transactions to serve as the anomaly score for the autoencoder model.\n",
    "\n",
    "- **Minimum error (~0.006)** corresponds to transactions that closely follow normal behavior and are well reconstructed by the model.\n",
    "- **Mean error (~0.205)** represents typical reconstruction quality for normal transactions.\n",
    "- **Standard deviation (~0.616)** indicates a clear spread in reconstruction errors, suggesting the presence of anomalous patterns.\n",
    "- **Maximum error (~38.55)** is significantly higher than the mean, indicating a small number of transactions that deviate strongly from normal behavior and are likely fraudulent.\n",
    "\n",
    "These results confirm that reconstruction error provides a meaningful and well-separated anomaly signal, which can be used for fraud scoring, probability estimation, and further evaluation.\n"
   ],
   "id": "c424acf8b7c214bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T04:04:24.193152100Z",
     "start_time": "2026-01-09T04:04:24.112161100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Thresholding for Autoencoder\n",
    "# -----------------------------\n",
    "# We flag the top X% highest reconstruction errors as anomalies.\n",
    "# This is consistent with unsupervised anomaly detection practice.\n",
    "\n",
    "# Choose threshold percentile (slightly higher than true fraud rate)\n",
    "THRESHOLD_PERCENTILE = 99.5  # top 0.5% most anomalous\n",
    "\n",
    "threshold = np.percentile(recon_error, THRESHOLD_PERCENTILE)\n",
    "\n",
    "# Binary predictions: 1 = fraud, 0 = normal\n",
    "y_pred_auto = (recon_error > threshold).astype(int)\n",
    "\n",
    "print(\"Autoencoder thresholding completed\")\n",
    "print(\"Threshold value:\", threshold)\n",
    "print(\"Predicted fraud count:\", y_pred_auto.sum())\n"
   ],
   "id": "56e37a4703939131",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder thresholding completed\n",
      "Threshold value: 1.9491261095898802\n",
      "Predicted fraud count: 287\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T04:06:30.781198Z",
     "start_time": "2026-01-09T04:06:30.537412100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Autoencoder Evaluation\n",
    "# -----------------------------\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# True labels\n",
    "y_true = y_val\n",
    "\n",
    "# Binary predictions from autoencoder\n",
    "y_pred = y_pred_auto\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, recon_error)\n",
    "\n",
    "print(\"Autoencoder Performance:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ],
   "id": "52b57d52c20aa70d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Performance:\n",
      "Precision: 0.7491\n",
      "Recall:    0.4370\n",
      "F1-score:  0.5520\n",
      "ROC-AUC:   0.9357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.75      0.44      0.55       492\n",
      "\n",
      "    accuracy                           0.99     57355\n",
      "   macro avg       0.87      0.72      0.77     57355\n",
      "weighted avg       0.99      0.99      0.99     57355\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56791    72]\n",
      " [  277   215]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T04:47:31.547790700Z",
     "start_time": "2026-01-09T04:47:31.107012400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Threshold Sensitivity Analysis\n",
    "# -----------------------------\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "for p in [99.5, 99.3, 99.1]:\n",
    "    threshold = np.percentile(recon_error, p)\n",
    "    y_pred_tmp = (recon_error > threshold).astype(int)\n",
    "\n",
    "    precision = precision_score(y_val, y_pred_tmp)\n",
    "    recall = recall_score(y_val, y_pred_tmp)\n",
    "    f1 = f1_score(y_val, y_pred_tmp)\n",
    "\n",
    "    print(f\"\\nThreshold Percentile: {p}\")\n",
    "    print(\"Predicted fraud count:\", y_pred_tmp.sum())\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n"
   ],
   "id": "5c70521031190c34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold Percentile: 99.5\n",
      "Predicted fraud count: 287\n",
      "Precision: 0.7491\n",
      "Recall:    0.4370\n",
      "F1-score:  0.5520\n",
      "\n",
      "Threshold Percentile: 99.3\n",
      "Predicted fraud count: 402\n",
      "Precision: 0.7214\n",
      "Recall:    0.5894\n",
      "F1-score:  0.6488\n",
      "\n",
      "Threshold Percentile: 99.1\n",
      "Predicted fraud count: 517\n",
      "Precision: 0.6441\n",
      "Recall:    0.6768\n",
      "F1-score:  0.6601\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Threshold Sensitivity Analysis\n",
    "\n",
    "The autoencoder produces a continuous reconstruction error score, which must be converted into a binary fraud decision using a threshold.\n",
    "Since anomaly detection models do not learn an explicit decision boundary, the choice of threshold directly controls the trade-off between **precision** (false positives) and **recall** (missed frauds).\n",
    "\n",
    "To analyze this trade-off, multiple percentile-based thresholds were evaluated:\n",
    "\n",
    "- **99.5 percentile** (top 0.5% anomalies):\n",
    "  - High precision (0.75)\n",
    "  - Lower recall (0.44)\n",
    "  - Conservative behavior with fewer false positives\n",
    "\n",
    "- **99.3 percentile** (top 0.7% anomalies):\n",
    "  - Improved recall (0.59)\n",
    "  - Slight reduction in precision (0.72)\n",
    "  - Better balance between false positives and missed frauds\n",
    "\n",
    "- **99.1 percentile** (top 0.9% anomalies):\n",
    "  - Highest recall (0.68)\n",
    "  - Lower precision (0.64)\n",
    "  - More aggressive fraud detection with increased false positives\n",
    "\n",
    "This analysis demonstrates that the autoencoder itself remains unchanged; only the **decision threshold** is adjusted to reflect different operational preferences.\n",
    "Lowering the threshold increases recall at the cost of additional false positives, which is a common and acceptable trade-off in fraud detection systems where missing fraudulent transactions is often more costly than reviewing extra alerts.\n"
   ],
   "id": "f6e977ecb532d517"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T04:58:21.950526500Z",
     "start_time": "2026-01-09T04:58:21.748502100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Final Autoencoder Evaluation (Selected Threshold)\n",
    "# -----------------------------\n",
    "# Using 99.3 percentile based on threshold sensitivity analysis\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Selected threshold\n",
    "FINAL_THRESHOLD_PERCENTILE = 99.3\n",
    "final_threshold = np.percentile(recon_error, FINAL_THRESHOLD_PERCENTILE)\n",
    "\n",
    "# Final binary predictions\n",
    "y_pred_final = (recon_error > final_threshold).astype(int)\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_val, y_pred_final)\n",
    "recall = recall_score(y_val, y_pred_final)\n",
    "f1 = f1_score(y_val, y_pred_final)\n",
    "roc_auc = roc_auc_score(y_val, recon_error)\n",
    "\n",
    "print(\"Final Autoencoder Evaluation (Threshold = 99.3 percentile)\")\n",
    "print(f\"Threshold value: {final_threshold:.4f}\")\n",
    "print(f\"Predicted fraud count: {y_pred_final.sum()}\")\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_final))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_final))\n"
   ],
   "id": "88f667bae035a319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Autoencoder Evaluation (Threshold = 99.3 percentile)\n",
      "Threshold value: 1.4625\n",
      "Predicted fraud count: 402\n",
      "\n",
      "Performance Metrics:\n",
      "Precision: 0.7214\n",
      "Recall:    0.5894\n",
      "F1-score:  0.6488\n",
      "ROC-AUC:   0.9357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.72      0.59      0.65       492\n",
      "\n",
      "    accuracy                           0.99     57355\n",
      "   macro avg       0.86      0.79      0.82     57355\n",
      "weighted avg       0.99      0.99      0.99     57355\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56751   112]\n",
      " [  202   290]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final Autoencoder Evaluation (Selected Threshold)\n",
    "\n",
    "Based on the threshold sensitivity analysis, the **99.3 percentile** of reconstruction error was selected as the final decision threshold for the autoencoder.\n",
    "\n",
    "### Threshold Details\n",
    "- **Threshold value:** 1.4625\n",
    "- **Predicted fraud transactions:** 402\n",
    "\n",
    "### Performance Metrics\n",
    "- **Precision:** 0.72\n",
    "- **Recall:** 0.59\n",
    "- **F1-score:** 0.65\n",
    "- **ROC-AUC:** 0.94\n",
    "\n",
    "### Confusion Matrix Interpretation\n",
    "- **True Positives (TP):** 290 fraud transactions correctly identified\n",
    "- **False Positives (FP):** 112 normal transactions incorrectly flagged\n",
    "- **False Negatives (FN):** 202 fraud transactions missed\n",
    "- **True Negatives (TN):** 56,751 normal transactions correctly classified\n",
    "\n",
    "### Interpretation\n",
    "The selected threshold provides a balanced trade-off between precision and recall.\n",
    "Compared to a more conservative threshold, recall improves significantly while precision remains strong, resulting in the highest F1-score achieved by the autoencoder.\n",
    "\n",
    "This confirms that the autoencoder, when combined with appropriate threshold tuning, can effectively detect fraudulent transactions while maintaining a manageable false-positive rate.\n"
   ],
   "id": "40e2b30d177e1db2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:26:12.765981600Z",
     "start_time": "2026-01-09T03:26:10.167563400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Environment & Library Check\n",
    "# -----------------------------\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ],
   "id": "d61c9cee3e57843a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
      "It can be downloaded at https://aka.ms/vs/17/release/vc_redist.x64.exe\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\rajth\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# -----------------------------\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# Environment & Library Check\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# -----------------------------\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msys\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mPython executable:\u001B[39m\u001B[33m\"\u001B[39m, sys.executable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\__init__.py:281\u001B[39m\n\u001B[32m    277\u001B[39m                     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[32m    279\u001B[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001B[32m--> \u001B[39m\u001B[32m281\u001B[39m     \u001B[43m_load_dll_libraries\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    282\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m _load_dll_libraries\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_cuda_dep_paths\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m, lib_folder: \u001B[38;5;28mstr\u001B[39m, lib_name: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    286\u001B[39m     \u001B[38;5;66;03m# Libraries can either be in\u001B[39;00m\n\u001B[32m    287\u001B[39m     \u001B[38;5;66;03m# path/nvidia/lib_folder/lib or\u001B[39;00m\n\u001B[32m    288\u001B[39m     \u001B[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001B[39;00m\n\u001B[32m    289\u001B[39m     \u001B[38;5;66;03m# path/lib_folder/lib\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\__init__.py:277\u001B[39m, in \u001B[36m_load_dll_libraries\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    273\u001B[39m             err = ctypes.WinError(ctypes.get_last_error())\n\u001B[32m    274\u001B[39m             err.strerror += (\n\u001B[32m    275\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m Error loading \u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m or one of its dependencies.\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    276\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[32m    279\u001B[39m kernel32.SetErrorMode(prev_error_mode)\n",
      "\u001B[31mOSError\u001B[39m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\rajth\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T03:15:51.064790300Z",
     "start_time": "2026-01-09T03:15:50.397755500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Imports & Load Preprocessing Artifacts\n",
    "# -----------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load preprocessing artifacts\n",
    "ARTIFACT_DIR = \"../models\"\n",
    "\n",
    "X_train_scaled = np.load(f\"{ARTIFACT_DIR}/X_train_scaled.npy\")\n",
    "X_val_scaled = np.load(f\"{ARTIFACT_DIR}/X_val_scaled.npy\")\n",
    "y_val = np.load(f\"{ARTIFACT_DIR}/y_val.npy\")\n",
    "\n",
    "print(\"Artifacts loaded successfully\")\n",
    "print(\"Train shape:\", X_train_scaled.shape)\n",
    "print(\"Validation shape:\", X_val_scaled.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)\n"
   ],
   "id": "719900c3b42792e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
      "It can be downloaded at https://aka.ms/vs/17/release/vc_redist.x64.exe\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\rajth\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      8\u001B[39m sys.path.append(os.path.abspath(\u001B[33m\"\u001B[39m\u001B[33m..\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DataLoader, TensorDataset\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\__init__.py:281\u001B[39m\n\u001B[32m    277\u001B[39m                     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[32m    279\u001B[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001B[32m--> \u001B[39m\u001B[32m281\u001B[39m     \u001B[43m_load_dll_libraries\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    282\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m _load_dll_libraries\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_cuda_dep_paths\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m, lib_folder: \u001B[38;5;28mstr\u001B[39m, lib_name: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    286\u001B[39m     \u001B[38;5;66;03m# Libraries can either be in\u001B[39;00m\n\u001B[32m    287\u001B[39m     \u001B[38;5;66;03m# path/nvidia/lib_folder/lib or\u001B[39;00m\n\u001B[32m    288\u001B[39m     \u001B[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001B[39;00m\n\u001B[32m    289\u001B[39m     \u001B[38;5;66;03m# path/lib_folder/lib\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\__init__.py:277\u001B[39m, in \u001B[36m_load_dll_libraries\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    273\u001B[39m             err = ctypes.WinError(ctypes.get_last_error())\n\u001B[32m    274\u001B[39m             err.strerror += (\n\u001B[32m    275\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m Error loading \u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m or one of its dependencies.\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    276\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[32m    279\u001B[39m kernel32.SetErrorMode(prev_error_mode)\n",
      "\u001B[31mOSError\u001B[39m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\rajth\\OneDrive\\Desktop\\Fraud_Anomaly_Detection\\.venv\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
